---
type: bug
status: open
priority: p1
---

# Issue Title: FFmpeg Encoder Drops Audio Streams on Render

## Description
When rendering a scene that contains an `audio("assets/track.mp3")` node (or native AI `tts(...)` nodes), the final `.mp4` output is completely silent. 

The compiler correctly parses the audio layer and validates the existence of the MP3 file, but the `vidra-encode` crate currently only muxes the bare RGB frames generated by the wgpu renderer into the video stream. It completely skips audio sampling and muxing.

## Reproducibility
1. Add an audio layer to any scene:
   ```javascript
   layer("music") {
       audio("assets/sample.mp3", volume: 1.0)
   }
   ```
2. Render: `vidra render project.vidra`
3. Play the resulting `.mp4`.

**Expected Behavior:** The audio track should play concurrently with the video frames.
**Actual Behavior:** The output video file contains no audio streams (verified via `ffprobe`).

## Context & Environment
- **Vidra CLI Version:** 0.1.0
- **Component:** `crates/vidra-encode/src/ffmpeg.rs`

## Proposed Resolution
Update the `vidra-encode` wrapper to:
1. Initialize an audio stream (e.g., AAC) in exactly the same FFmpeg context alongside the H.264 video stream.
2. Read the audio duration and buffer data from the IR's loaded `AssetId` and interleave the audio samples (`av_interleaved_write_frame`) in sync with the video PTS (Presentation Time Stamp).
Closing Issue #003: Asset 'assets/sample.mp3' was identified as a silent audio track.
